{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from langchain.vectorstores.chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma\"\n",
    "DATA_PATH = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "\n",
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(path=\"data\")\n",
    "    return document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    # Remove multiple spaces and unnecessary line breaks\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single one\n",
    "    text = text.strip()  # Remove spaces at the beginning and end\n",
    "    return text\n",
    "\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800, #essayer avec 500\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False\n",
    "    )\n",
    "    \n",
    "    # Nettoyage avant la sÃ©paration\n",
    "    cleaned_documents = [Document(page_content=preprocess_text(doc.page_content), metadata=doc.metadata) for doc in documents]\n",
    "    return text_splitter.split_documents(cleaned_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_documents()\n",
    "chunks = split_documents(documents)\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "\n",
    "def get_embedding_function():\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chunk_ids(chunks):\n",
    "\n",
    "    # This will create IDs like \"data/monopoly.pdf:6:2\"\n",
    "    # Page Source : Page Number : Chunk Index\n",
    "\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        # If the page ID is the same as the last one, increment the index.\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        # Calculate the chunk ID.\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "\n",
    "        # Add it to the page meta-data.\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "def store_chunks_in_chroma(chunks):\n",
    "    # Initialize the embedding model\n",
    "    embedding_function = get_embedding_function()\n",
    "    \n",
    "    # Initialize the Chroma database and add the chunks\n",
    "    vectorstore = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "    vectorstore.add_documents(chunks)\n",
    "    \n",
    "    # Save the vector database to disk\n",
    "    vectorstore.persist()\n",
    "    print(f\"âœ… {len(chunks)} chunks stored successfully in Chroma!\")\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "# Calling the function\n",
    "chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "vectorstore = store_chunks_in_chroma(chunks_with_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chroma(query):\n",
    "    # Load the existing database\n",
    "    vectorstore = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function())\n",
    "    \n",
    "    # Perform a similarity search\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    \n",
    "    print(\"\\nðŸ”Ž Query Results:\")\n",
    "    for result in results:\n",
    "        print(f\"Source: {result.metadata['source']}\")\n",
    "        print(f\"Chunk: {result.page_content}\\n\")\n",
    "        \n",
    "# Example query\n",
    "query_chroma(\"Quel est le code Ã©tablissement pour l'application SoWeSign ?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_chroma(\"Est-il autorisÃ© de fumer dans l'enceinte de l'Ã©cole ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-kii4reU9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
